{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-13T10:32:55.200660Z","iopub.execute_input":"2024-09-13T10:32:55.201171Z","iopub.status.idle":"2024-09-13T10:32:55.645560Z","shell.execute_reply.started":"2024-09-13T10:32:55.201125Z","shell.execute_reply":"2024-09-13T10:32:55.644237Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"pip install datasets\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T10:32:55.647847Z","iopub.execute_input":"2024-09-13T10:32:55.648333Z","iopub.status.idle":"2024-09-13T10:33:12.571931Z","shell.execute_reply.started":"2024-09-13T10:32:55.648291Z","shell.execute_reply":"2024-09-13T10:33:12.570560Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Requirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from datasets) (3.15.1)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from datasets) (1.26.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: requests>=2.32.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (2.32.3)\nRequirement already satisfied: tqdm>=4.66.3 in /opt/conda/lib/python3.10/site-packages (from datasets) (4.66.4)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: huggingface-hub>=0.21.2 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.24.6)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from datasets) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from datasets) (6.0.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub>=0.21.2->datasets) (4.12.2)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->datasets) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests>=2.32.2->datasets) (2024.7.4)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"code","source":"from datasets import load_dataset\n\n# Replace with your dataset name and username\ndataset = load_dataset(\"DSE-project-sem-5/Emotion-Data-for-nlp\", token=\"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\")\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T10:33:12.573504Z","iopub.execute_input":"2024-09-13T10:33:12.573884Z","iopub.status.idle":"2024-09-13T10:33:17.152467Z","shell.execute_reply.started":"2024-09-13T10:33:12.573844Z","shell.execute_reply":"2024-09-13T10:33:17.151368Z"},"trusted":true},"execution_count":3,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading readme:   0%|          | 0.00/506 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"eb679b1b723e48eaaa9927b64bd588da"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/688k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"74d4a115a70e4962a337e0980b3c9d34"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/86.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d4b4ee3d8c914811a8b6de1f1324aa70"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading data:   0%|          | 0.00/85.2k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"af2a459e149f4eab92648f35c2936b38"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1aec6b3249864739b41dce0c8536a706"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating test split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6ca300270456441c903949c0207a30b8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating val split:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e902f43d24d74f809b7f73f1e36a7c43"}},"metadata":{}}]},{"cell_type":"code","source":"# Access dataset parts\ntrain = dataset[\"train\"].to_pandas()\ntest = dataset[\"test\"].to_pandas()\nval = dataset[\"val\"].to_pandas()\n\n# Print first few rows of dataset1\ntest.head()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:18:09.180384Z","iopub.execute_input":"2024-09-13T11:18:09.180867Z","iopub.status.idle":"2024-09-13T11:18:09.204015Z","shell.execute_reply.started":"2024-09-13T11:18:09.180819Z","shell.execute_reply":"2024-09-13T11:18:09.202805Z"},"trusted":true},"execution_count":53,"outputs":[{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"                                               Input Sentiment\n0         m feeling rather rotten im ambitious right   sadness\n1                        m updating blog feel shitty   sadness\n2          ever make separate ever want feel ashamed   sadness\n3  eft bouquet red yellow tulips arm feeling slig...       joy\n4                            feeling little vain one   sadness","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Input</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>m feeling rather rotten im ambitious right</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>m updating blog feel shitty</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>ever make separate ever want feel ashamed</td>\n      <td>sadness</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>eft bouquet red yellow tulips arm feeling slig...</td>\n      <td>joy</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>feeling little vain one</td>\n      <td>sadness</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"!pip install transformers torch\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T10:33:17.197485Z","iopub.execute_input":"2024-09-13T10:33:17.198433Z","iopub.status.idle":"2024-09-13T10:33:32.692178Z","shell.execute_reply.started":"2024-09-13T10:33:17.198386Z","shell.execute_reply":"2024-09-13T10:33:32.690686Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.24.6)\nRequirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch) (2024.6.1)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch) (2.1.5)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.7.4)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import RobertaTokenizer, RobertaForSequenceClassification\n\n# Load the RoBERTa tokenizer\ntokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n\n# Load the RoBERTa model for sequence classification with 5 output classes\nmodel = RobertaForSequenceClassification.from_pretrained('roberta-base', num_labels=5)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T10:33:32.693981Z","iopub.execute_input":"2024-09-13T10:33:32.694436Z","iopub.status.idle":"2024-09-13T10:33:42.080619Z","shell.execute_reply.started":"2024-09-13T10:33:32.694392Z","shell.execute_reply":"2024-09-13T10:33:42.079448Z"},"trusted":true},"execution_count":6,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/25.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"300c102c0d87486fa1f29cabbd5ff137"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8522674afb0346ec86a7b4aa4d769129"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0a2eacb019114f20a42dd8ff05060a7a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"13a01aa9419d4a8b9434db129a1ad33c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/481 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5b44a8bc00f94be5902af8130ef2719e"}},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/499M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a918cbbbe2641ebb6f52c90d7325aad"}},"metadata":{}},{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers datasets huggingface_hub tensorboard==2.11\n!sudo apt-get install git-lfs --yes","metadata":{"execution":{"iopub.status.busy":"2024-09-13T10:33:42.082213Z","iopub.execute_input":"2024-09-13T10:33:42.082949Z","iopub.status.idle":"2024-09-13T10:34:04.978280Z","shell.execute_reply.started":"2024-09-13T10:33:42.082905Z","shell.execute_reply":"2024-09-13T10:34:04.976951Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.44.0)\nRequirement already satisfied: datasets in /opt/conda/lib/python3.10/site-packages (2.21.0)\nRequirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.24.6)\nCollecting tensorboard==2.11\n  Downloading tensorboard-2.11.0-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: absl-py>=0.4 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (1.4.0)\nRequirement already satisfied: grpcio>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (1.64.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (2.30.0)\nCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard==2.11)\n  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl.metadata (2.7 kB)\nRequirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (3.6)\nRequirement already satisfied: numpy>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (1.26.4)\nRequirement already satisfied: protobuf<4,>=3.9.2 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (3.20.3)\nRequirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (2.32.3)\nRequirement already satisfied: setuptools>=41.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (70.0.0)\nCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard==2.11)\n  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl.metadata (1.1 kB)\nCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard==2.11)\n  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl.metadata (873 bytes)\nRequirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (3.0.3)\nRequirement already satisfied: wheel>=0.26 in /opt/conda/lib/python3.10/site-packages (from tensorboard==2.11) (0.43.0)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\nRequirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.4)\nRequirement already satisfied: tokenizers<0.20,>=0.19 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.19.1)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\nRequirement already satisfied: pyarrow>=15.0.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (17.0.0)\nRequirement already satisfied: dill<0.3.9,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from datasets) (0.3.8)\nRequirement already satisfied: pandas in /opt/conda/lib/python3.10/site-packages (from datasets) (2.2.2)\nRequirement already satisfied: xxhash in /opt/conda/lib/python3.10/site-packages (from datasets) (3.4.1)\nRequirement already satisfied: multiprocess in /opt/conda/lib/python3.10/site-packages (from datasets) (0.70.16)\nRequirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /opt/conda/lib/python3.10/site-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\nRequirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from datasets) (3.9.5)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.12.2)\nRequirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.3.1)\nRequirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (23.2.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.4.1)\nRequirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (6.0.5)\nRequirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (1.9.4)\nRequirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->datasets) (4.0.3)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.11) (4.2.4)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.11) (0.4.0)\nRequirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard==2.11) (4.9)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.11) (2.0.0)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.11) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.11) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.11) (1.26.18)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard==2.11) (2024.7.4)\nRequirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard==2.11) (2.1.5)\nRequirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: tzdata>=2022.7 in /opt/conda/lib/python3.10/site-packages (from pandas->datasets) (2024.1)\nRequirement already satisfied: pyasn1<0.7.0,>=0.4.6 in /opt/conda/lib/python3.10/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard==2.11) (0.6.0)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\nRequirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard==2.11) (3.2.2)\nDownloading tensorboard-2.11.0-py3-none-any.whl (6.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\nDownloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: tensorboard-plugin-wit, tensorboard-data-server, google-auth-oauthlib, tensorboard\n  Attempting uninstall: tensorboard-data-server\n    Found existing installation: tensorboard-data-server 0.7.2\n    Uninstalling tensorboard-data-server-0.7.2:\n      Successfully uninstalled tensorboard-data-server-0.7.2\n  Attempting uninstall: google-auth-oauthlib\n    Found existing installation: google-auth-oauthlib 1.2.0\n    Uninstalling google-auth-oauthlib-1.2.0:\n      Successfully uninstalled google-auth-oauthlib-1.2.0\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.16.2\n    Uninstalling tensorboard-2.16.2:\n      Successfully uninstalled tensorboard-2.16.2\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ntensorflow 2.16.1 requires tensorboard<2.17,>=2.16, but you have tensorboard 2.11.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed google-auth-oauthlib-0.4.6 tensorboard-2.11.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1\nReading package lists... Done\nBuilding dependency tree       \nReading state information... Done\ngit-lfs is already the newest version (2.9.2-1).\n0 upgraded, 0 newly installed, 0 to remove and 30 not upgraded.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom datasets import load_dataset\nfrom transformers import (\n    RobertaTokenizerFast,\n    RobertaForSequenceClassification,\n    TrainingArguments,\n    Trainer,\n    AutoConfig,\n)\nfrom huggingface_hub import HfFolder, notebook_login","metadata":{"execution":{"iopub.status.busy":"2024-09-13T10:34:04.980207Z","iopub.execute_input":"2024-09-13T10:34:04.980637Z","iopub.status.idle":"2024-09-13T10:34:21.549052Z","shell.execute_reply.started":"2024-09-13T10:34:04.980594Z","shell.execute_reply":"2024-09-13T10:34:21.548056Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"model_id = \"roberta-base\"\n# relace the value with your model: ex <hugging-face-user>/<model-name>\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T10:34:21.550540Z","iopub.execute_input":"2024-09-13T10:34:21.551501Z","iopub.status.idle":"2024-09-13T10:34:21.557163Z","shell.execute_reply.started":"2024-09-13T10:34:21.551444Z","shell.execute_reply":"2024-09-13T10:34:21.555845Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"train = Dataset.from_pandas(train).rename_column(\"Sentiment\", \"label\").rename_column(\"Input\", \"text\")\nval = Dataset.from_pandas(val).rename_column(\"Sentiment\", \"label\").rename_column(\"Input\", \"text\")\ntest = Dataset.from_pandas(test).rename_column(\"Sentiment\", \"label\").rename_column(\"Input\", \"text\")","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:18:18.805756Z","iopub.execute_input":"2024-09-13T11:18:18.806374Z","iopub.status.idle":"2024-09-13T11:18:18.868996Z","shell.execute_reply.started":"2024-09-13T11:18:18.806309Z","shell.execute_reply":"2024-09-13T11:18:18.867896Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\ntokenizer = RobertaTokenizerFast.from_pretrained(model_id)\n\n# This function tokenizes the input text using the RoBERTa tokenizer. \n# It applies padding and truncation to ensure that all sequences have the same length (256 tokens).\ndef tokenize(batch):\n    return tokenizer(batch[\"text\"], padding=True, truncation=True, max_length=256)\n\ntrain = train.map(tokenize, batched=True, batch_size=len(train))\nval = val.map(tokenize, batched=True, batch_size=len(val))\ntest = test.map(tokenize, batched=True, batch_size=len(test))","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:18:22.177063Z","iopub.execute_input":"2024-09-13T11:18:22.177469Z","iopub.status.idle":"2024-09-13T11:18:24.065706Z","shell.execute_reply.started":"2024-09-13T11:18:22.177431Z","shell.execute_reply":"2024-09-13T11:18:24.064603Z"},"trusted":true},"execution_count":55,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4b90000d355f4a31bed53ce3802dc22b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7806a8d0112b4c4eb4c92622124827b2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d39726fdd468419fad9ffeaaf5582a37"}},"metadata":{}}]},{"cell_type":"code","source":"train","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:17:27.241631Z","iopub.execute_input":"2024-09-13T11:17:27.242391Z","iopub.status.idle":"2024-09-13T11:17:27.249261Z","shell.execute_reply.started":"2024-09-13T11:17:27.242345Z","shell.execute_reply":"2024-09-13T11:17:27.248167Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['text', 'labels', 'input_ids', 'attention_mask'],\n    num_rows: 16000\n})"},"metadata":{}}]},{"cell_type":"code","source":"train.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\nval.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\ntest.set_format(\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:18:32.825928Z","iopub.execute_input":"2024-09-13T11:18:32.826458Z","iopub.status.idle":"2024-09-13T11:18:32.836064Z","shell.execute_reply.started":"2024-09-13T11:18:32.826408Z","shell.execute_reply":"2024-09-13T11:18:32.834812Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"dataset['train'].features['Sentiment']","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:23:23.497771Z","iopub.execute_input":"2024-09-13T11:23:23.498203Z","iopub.status.idle":"2024-09-13T11:23:23.505626Z","shell.execute_reply.started":"2024-09-13T11:23:23.498164Z","shell.execute_reply":"2024-09-13T11:23:23.504509Z"},"trusted":true},"execution_count":64,"outputs":[{"execution_count":64,"output_type":"execute_result","data":{"text/plain":"Value(dtype='string', id=None)"},"metadata":{}}]},{"cell_type":"code","source":"num_labels = dataset['train'].features['Sentiment']\nclass_names = dataset[\"train\"].features[\"Sentiment\"].names","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:23:07.887280Z","iopub.execute_input":"2024-09-13T11:23:07.887760Z","iopub.status.idle":"2024-09-13T11:23:07.944598Z","shell.execute_reply.started":"2024-09-13T11:23:07.887717Z","shell.execute_reply":"2024-09-13T11:23:07.943244Z"},"trusted":true},"execution_count":63,"outputs":[{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[63], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_labels \u001b[38;5;241m=\u001b[39m \u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeatures\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSentiment\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclasses\u001b[49m\n\u001b[1;32m      2\u001b[0m class_names \u001b[38;5;241m=\u001b[39m dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mfeatures[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSentiment\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mnames\n","\u001b[0;31mAttributeError\u001b[0m: 'Value' object has no attribute 'classes'"],"ename":"AttributeError","evalue":"'Value' object has no attribute 'classes'","output_type":"error"}]},{"cell_type":"code","source":"num_labels = 5\nclass_names = [\"sadness\", \"fear\", \"anger\", \"joy\", \"surprise\",\"love\"]\nprint(f\"number of labels: {num_labels}\")\nprint(f\"the labels: {class_names}\")\n\n# Create an id2label mapping\nid2label = {i: label for i, label in enumerate(class_names)}\n\n# Update the model's configuration with the id2label mapping\nconfig = AutoConfig.from_pretrained(model_id)\nconfig.update({\"id2label\": id2label})","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:24:49.790670Z","iopub.execute_input":"2024-09-13T11:24:49.791861Z","iopub.status.idle":"2024-09-13T11:24:49.904206Z","shell.execute_reply.started":"2024-09-13T11:24:49.791800Z","shell.execute_reply":"2024-09-13T11:24:49.902738Z"},"trusted":true},"execution_count":65,"outputs":[{"name":"stdout","text":"number of labels: 5\nthe labels: ['sadness', 'fear', 'anger', 'joy', 'surprise', 'love']\n","output_type":"stream"}]},{"cell_type":"code","source":"id2label","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:26:30.555621Z","iopub.execute_input":"2024-09-13T11:26:30.556120Z","iopub.status.idle":"2024-09-13T11:26:30.563736Z","shell.execute_reply.started":"2024-09-13T11:26:30.556074Z","shell.execute_reply":"2024-09-13T11:26:30.562570Z"},"trusted":true},"execution_count":68,"outputs":[{"execution_count":68,"output_type":"execute_result","data":{"text/plain":"{0: 'sadness', 1: 'fear', 2: 'anger', 3: 'joy', 4: 'surprise', 5: 'love'}"},"metadata":{}}]},{"cell_type":"code","source":"# Model\nmodel = RobertaForSequenceClassification.from_pretrained(model_id, config=config)\nrepository_id = \"DSE-project-sem-5/Roberta-model\"\n# TrainingArguments\ntraining_args = TrainingArguments(\n    output_dir=repository_id,\n    num_train_epochs=5,\n    per_device_train_batch_size=8,\n    per_device_eval_batch_size=8,\n    evaluation_strategy=\"epoch\",\n    logging_dir=f\"{repository_id}/logs\",\n    logging_strategy=\"steps\",\n    logging_steps=10,\n    learning_rate=5e-5,\n    weight_decay=0.01,\n    warmup_steps=500,\n    save_strategy=\"epoch\",\n    load_best_model_at_end=True,\n    save_total_limit=2,\n    report_to=\"tensorboard\",\n    push_to_hub=False,\n#     hub_strategy=\"every_save\",\n#     hub_model_id=repository_id,\n#     hub_token=\"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\",\n)\n\n\n# Trainer\ntrainer = Trainer(\n    model=model,\n    args=training_args,\n    train_dataset=train,\n    eval_dataset=val,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:37:29.449040Z","iopub.execute_input":"2024-09-13T11:37:29.449510Z","iopub.status.idle":"2024-09-13T11:37:29.565811Z","shell.execute_reply.started":"2024-09-13T11:37:29.449464Z","shell.execute_reply":"2024-09-13T11:37:29.564684Z"},"trusted":true},"execution_count":81,"outputs":[{"name":"stderr","text":"Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"label_mapping = {\n    'sadness': 0,\n    'fear': 1,\n    'anger': 2,\n    'joy': 3,\n    'surprise': 4,\n    'love': 5\n}\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:30:03.708017Z","iopub.execute_input":"2024-09-13T11:30:03.709136Z","iopub.status.idle":"2024-09-13T11:30:03.714592Z","shell.execute_reply.started":"2024-09-13T11:30:03.709085Z","shell.execute_reply":"2024-09-13T11:30:03.713171Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"from datasets import Dataset\n\ndef encode_labels(example):\n    example['label'] = label_mapping[example['label']]\n    return example\n\n# Apply encoding to the dataset\ntrain = train.map(encode_labels)\nval = val.map(encode_labels)\ntest = test.map(encode_labels)\n\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:30:29.295410Z","iopub.execute_input":"2024-09-13T11:30:29.295913Z","iopub.status.idle":"2024-09-13T11:30:41.459522Z","shell.execute_reply.started":"2024-09-13T11:30:29.295867Z","shell.execute_reply":"2024-09-13T11:30:41.458415Z"},"trusted":true},"execution_count":74,"outputs":[{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/16000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbc3d957627245c89c620b0703fdbaa2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1117e7122b4a480d9dcc3f17a46c3b37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/2000 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d0c0e47ca112442b98c1cc9c96edfdf4"}},"metadata":{}}]},{"cell_type":"code","source":"df_tttt = train.to_pandas()","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:30:43.982617Z","iopub.execute_input":"2024-09-13T11:30:43.983639Z","iopub.status.idle":"2024-09-13T11:30:44.019538Z","shell.execute_reply.started":"2024-09-13T11:30:43.983588Z","shell.execute_reply":"2024-09-13T11:30:44.018447Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"df_tttt.head()","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:30:46.137453Z","iopub.execute_input":"2024-09-13T11:30:46.138267Z","iopub.status.idle":"2024-09-13T11:30:46.162419Z","shell.execute_reply.started":"2024-09-13T11:30:46.138222Z","shell.execute_reply":"2024-09-13T11:30:46.161143Z"},"trusted":true},"execution_count":76,"outputs":[{"execution_count":76,"output_type":"execute_result","data":{"text/plain":"                                                text  label  \\\n0                              didnt feel humiliated      0   \n1  go feeling hopeless damned hopeful around some...      0   \n2           m grabbing minute post feel greedy wrong      2   \n3  ever feeling nostalgic fireplace know still pr...      5   \n4                                    feeling grouchy      2   \n\n                                           input_ids  \\\n0  [0, 24001, 3999, 619, 32386, 2, 1, 1, 1, 1, 1,...   \n1  [0, 2977, 2157, 24418, 37689, 7917, 198, 951, ...   \n2  [0, 119, 16004, 2289, 618, 619, 34405, 1593, 2...   \n3  [0, 6294, 2157, 28055, 24672, 216, 202, 1038, ...   \n4  [0, 7068, 10244, 22970, 17414, 2, 1, 1, 1, 1, ...   \n\n                                      attention_mask  \n0  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  \n1  [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...  \n2  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n3  [1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...  \n4  [1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n      <th>input_ids</th>\n      <th>attention_mask</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>didnt feel humiliated</td>\n      <td>0</td>\n      <td>[0, 24001, 3999, 619, 32386, 2, 1, 1, 1, 1, 1,...</td>\n      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>go feeling hopeless damned hopeful around some...</td>\n      <td>0</td>\n      <td>[0, 2977, 2157, 24418, 37689, 7917, 198, 951, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>m grabbing minute post feel greedy wrong</td>\n      <td>2</td>\n      <td>[0, 119, 16004, 2289, 618, 619, 34405, 1593, 2...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ever feeling nostalgic fireplace know still pr...</td>\n      <td>5</td>\n      <td>[0, 6294, 2157, 28055, 24672, 216, 202, 1038, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>feeling grouchy</td>\n      <td>2</td>\n      <td>[0, 7068, 10244, 22970, 17414, 2, 1, 1, 1, 1, ...</td>\n      <td>[1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train = train.shuffle(seed=42).select(range(int(len(train) * 0.1)))\nval = val.shuffle(seed=42).select(range(int(len(val) * 0.1)))","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:36:58.799708Z","iopub.execute_input":"2024-09-13T11:36:58.800298Z","iopub.status.idle":"2024-09-13T11:36:58.843664Z","shell.execute_reply.started":"2024-09-13T11:36:58.800251Z","shell.execute_reply":"2024-09-13T11:36:58.842327Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"trainer.train()\n","metadata":{"execution":{"iopub.status.busy":"2024-09-13T11:37:41.352938Z","iopub.execute_input":"2024-09-13T11:37:41.353393Z","iopub.status.idle":"2024-09-13T11:40:24.515002Z","shell.execute_reply.started":"2024-09-13T11:37:41.353346Z","shell.execute_reply":"2024-09-13T11:40:24.513211Z"},"trusted":true},"execution_count":82,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='45' max='1000' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [  45/1000 02:34 < 57:09, 0.28 it/s, Epoch 0.22/5]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n  </tbody>\n</table><p>"},"metadata":{}},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[82], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:1948\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1946\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1947\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1948\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1949\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1950\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1951\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1952\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1953\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:2289\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2286\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   2288\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 2289\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2291\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   2292\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   2293\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[1;32m   2294\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   2295\u001b[0m ):\n\u001b[1;32m   2296\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   2297\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/trainer.py:3359\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m   3357\u001b[0m         scaled_loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m   3358\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3359\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3361\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\u001b[38;5;241m.\u001b[39mdetach() \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mgradient_accumulation_steps\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/accelerate/accelerator.py:2159\u001b[0m, in \u001b[0;36mAccelerator.backward\u001b[0;34m(self, loss, **kwargs)\u001b[0m\n\u001b[1;32m   2157\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlomo_backward(loss, learning_rate)\n\u001b[1;32m   2158\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2159\u001b[0m     \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}