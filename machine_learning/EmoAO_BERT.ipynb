{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Classify emotions in text with BERT NLP model "]},{"cell_type":"code","execution_count":3,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-10-21T05:38:41.913041Z","iopub.status.busy":"2024-10-21T05:38:41.912648Z","iopub.status.idle":"2024-10-21T05:38:42.279385Z","shell.execute_reply":"2024-10-21T05:38:42.278449Z","shell.execute_reply.started":"2024-10-21T05:38:41.913002Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["/kaggle/input/emotions-dataset-for-nlp/val.txt\n","/kaggle/input/emotions-dataset-for-nlp/test.txt\n","/kaggle/input/emotions-dataset-for-nlp/train.txt\n"]}],"source":["# This Python 3 environment comes with many helpful analytics libraries installed\n","# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n","# For example, here's several helpful packages to load in \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","\n","# Input data files are available in the \"../input/\" directory.\n","# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n","\n","import os\n","for dirname, _, filenames in os.walk('/kaggle/input'):\n","    for filename in filenames:\n","        print(os.path.join(dirname, filename))\n","\n","# Any results you write to the current directory are saved as output."]},{"cell_type":"code","execution_count":4,"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","execution":{"iopub.execute_input":"2024-10-21T05:38:43.960419Z","iopub.status.busy":"2024-10-21T05:38:43.959393Z","iopub.status.idle":"2024-10-21T05:38:55.474874Z","shell.execute_reply":"2024-10-21T05:38:55.473862Z","shell.execute_reply.started":"2024-10-21T05:38:43.960372Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.45.1)\n","Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.15.1)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.25.1)\n","Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\n","Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2024.5.15)\n","Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.32.3)\n","Requirement already satisfied: safetensors>=0.4.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.5)\n","Requirement already satisfied: tokenizers<0.21,>=0.20 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.0)\n","Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.4)\n","Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.6.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.1.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.7)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2024.8.30)\n"]}],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:39:39.553289Z","iopub.status.busy":"2024-10-21T05:39:39.552199Z","iopub.status.idle":"2024-10-21T05:39:43.069161Z","shell.execute_reply":"2024-10-21T05:39:43.068342Z","shell.execute_reply.started":"2024-10-21T05:39:39.553229Z"},"trusted":true},"outputs":[],"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","import torch.nn.functional as F\n","from transformers import BertTokenizer, BertConfig,AdamW, BertForSequenceClassification,get_linear_schedule_with_warmup\n","\n","\n","import pandas as pd\n","import numpy as np\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import confusion_matrix,classification_report\n","# Import and evaluate each test batch using Matthew's correlation coefficient\n","from sklearn.metrics import accuracy_score,matthews_corrcoef\n","\n","from tqdm import tqdm, trange,tnrange,tqdm_notebook\n","import random\n","import os\n","import io\n","# % matplotlib inline"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:39:49.634754Z","iopub.status.busy":"2024-10-21T05:39:49.633668Z","iopub.status.idle":"2024-10-21T05:39:49.690697Z","shell.execute_reply":"2024-10-21T05:39:49.689891Z","shell.execute_reply.started":"2024-10-21T05:39:49.634709Z"},"trusted":true},"outputs":[],"source":["# identify and specify the GPU as the device, later in training loop we will load data into device\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","n_gpu = torch.cuda.device_count()\n","torch.cuda.get_device_name(0)\n","\n","SEED = 19\n","\n","random.seed(SEED)\n","np.random.seed(SEED)\n","torch.manual_seed(SEED)\n","if device == torch.device(\"cuda\"):\n","    torch.cuda.manual_seed_all(SEED)"]},{"cell_type":"code","execution_count":7,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:39:51.555936Z","iopub.status.busy":"2024-10-21T05:39:51.555527Z","iopub.status.idle":"2024-10-21T05:39:51.560495Z","shell.execute_reply":"2024-10-21T05:39:51.559375Z","shell.execute_reply.started":"2024-10-21T05:39:51.555898Z"},"trusted":true},"outputs":[],"source":["device = torch.device(\"cuda\")"]},{"cell_type":"markdown","metadata":{},"source":["BertTokenizer to run end-to-end tokenization: punctuation splitting + word piece. \n","BertForSequenceClassification is the Bert Model transformer with a sequence classification/regression head on top (a linear layer on top of the pooled output). \n","BertConfig is the configuration class to store model configurations. \n","AdamW implements Adam learning rate optimization algorithm, it is a type of Stochastic Gradient Descent with momentum. Here momentum is described as the moving average of the gradient instead of gradient itself.\n","get_linear_schedule_with_warmup creates a schedule with a learning rate that decreases linearly after linearly increasing during a warm-up period."]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:39:54.670526Z","iopub.status.busy":"2024-10-21T05:39:54.669623Z","iopub.status.idle":"2024-10-21T05:39:54.720429Z","shell.execute_reply":"2024-10-21T05:39:54.719614Z","shell.execute_reply.started":"2024-10-21T05:39:54.670483Z"},"trusted":true},"outputs":[],"source":["df_train = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/train.txt\", delimiter=';', header=None, names=['sentence','label'])\n","df_test = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/test.txt\", delimiter=';', header=None, names=['sentence','label'])\n","df_val = pd.read_csv(\"/kaggle/input/emotions-dataset-for-nlp/val.txt\", delimiter=';', header=None, names=['sentence','label'])"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:39:55.842309Z","iopub.status.busy":"2024-10-21T05:39:55.841870Z","iopub.status.idle":"2024-10-21T05:39:55.848770Z","shell.execute_reply":"2024-10-21T05:39:55.847777Z","shell.execute_reply.started":"2024-10-21T05:39:55.842267Z"},"trusted":true},"outputs":[],"source":["df = pd.concat([df_train,df_test,df_val])"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:39:57.049788Z","iopub.status.busy":"2024-10-21T05:39:57.049367Z","iopub.status.idle":"2024-10-21T05:39:57.059096Z","shell.execute_reply":"2024-10-21T05:39:57.058158Z","shell.execute_reply.started":"2024-10-21T05:39:57.049751Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array(['sadness', 'anger', 'love', 'surprise', 'fear', 'joy'],\n","      dtype=object)"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["df['label'].unique()"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:39:58.103534Z","iopub.status.busy":"2024-10-21T05:39:58.103121Z","iopub.status.idle":"2024-10-21T05:39:58.115131Z","shell.execute_reply":"2024-10-21T05:39:58.114135Z","shell.execute_reply.started":"2024-10-21T05:39:58.103495Z"},"trusted":true},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","labelencoder = LabelEncoder()\n","df['label_enc'] = labelencoder.fit_transform(df['label'])"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:39:59.216408Z","iopub.status.busy":"2024-10-21T05:39:59.215714Z","iopub.status.idle":"2024-10-21T05:39:59.232933Z","shell.execute_reply":"2024-10-21T05:39:59.232025Z","shell.execute_reply.started":"2024-10-21T05:39:59.216363Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>label_enc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>sadness</td>\n","      <td>4</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>anger</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>love</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>surprise</td>\n","      <td>5</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>fear</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>joy</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["      label  label_enc\n","0   sadness          4\n","2     anger          0\n","3      love          3\n","6  surprise          5\n","7      fear          1\n","8       joy          2"]},"execution_count":12,"metadata":{},"output_type":"execute_result"}],"source":["df[['label','label_enc']].drop_duplicates(keep='first')"]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:40:00.717693Z","iopub.status.busy":"2024-10-21T05:40:00.716915Z","iopub.status.idle":"2024-10-21T05:40:00.722979Z","shell.execute_reply":"2024-10-21T05:40:00.722013Z","shell.execute_reply.started":"2024-10-21T05:40:00.717649Z"},"trusted":true},"outputs":[],"source":["df.rename(columns={'label':'label_desc'},inplace=True)\n","df.rename(columns={'label_enc':'label'},inplace=True)"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:40:04.043895Z","iopub.status.busy":"2024-10-21T05:40:04.043175Z","iopub.status.idle":"2024-10-21T05:40:20.005025Z","shell.execute_reply":"2024-10-21T05:40:20.003832Z","shell.execute_reply.started":"2024-10-21T05:40:04.043854Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"]},{"name":"stdout","output_type":"stream","text":["Distribution of data based on labels:  label\n","2    6761\n","4    5797\n","0    2709\n","1    2373\n","3    1641\n","5     719\n","Name: count, dtype: int64\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2837: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Actual sentence before tokenization:  im grabbing a minute to post i feel greedy wrong\n","Encoded Input from dataset:  [101, 10047, 9775, 1037, 3371, 2000, 2695, 1045, 2514, 20505, 3308, 102, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"]}],"source":["## create label and sentence list\n","sentences = df.sentence.values\n","\n","#check distribution of data based on labels\n","print(\"Distribution of data based on labels: \",df.label.value_counts())\n","\n","# Set the maximum sequence length. The longest sequence in our training set is 47, but we'll leave room on the end anyway. \n","# In the original paper, the authors used a length of 512.\n","MAX_LEN = 256\n","\n","## Import BERT tokenizer, that is used to convert our text into tokens that corresponds to BERT library\n","tokenizer = BertTokenizer.from_pretrained('bert-base-uncased',do_lower_case=True, truncation=True)\n","input_ids = [tokenizer.encode(sent, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True) for sent in sentences]\n","labels = df.label.values\n","\n","print(\"Actual sentence before tokenization: \",sentences[2])\n","print(\"Encoded Input from dataset: \",input_ids[2])\n","\n","## Create attention mask\n","attention_masks = []\n","## Create a mask of 1 for all input tokens and 0 for all padding tokens\n","attention_masks = [[float(i>0) for i in seq] for seq in input_ids]\n","print(attention_masks[2])"]},{"cell_type":"markdown","metadata":{},"source":["## Dataset Prep for training"]},{"cell_type":"markdown","metadata":{},"source":["#### Split into a training set and a test set using a stratified k fold"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:40:28.134647Z","iopub.status.busy":"2024-10-21T05:40:28.133740Z","iopub.status.idle":"2024-10-21T05:40:28.156534Z","shell.execute_reply":"2024-10-21T05:40:28.155782Z","shell.execute_reply.started":"2024-10-21T05:40:28.134604Z"},"trusted":true},"outputs":[],"source":["train_inputs,validation_inputs,train_labels,validation_labels = train_test_split(input_ids,labels,random_state=41,test_size=0.1)\n","train_masks,validation_masks,_,_ = train_test_split(attention_masks,input_ids,random_state=41,test_size=0.1)"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:40:29.996282Z","iopub.status.busy":"2024-10-21T05:40:29.995833Z","iopub.status.idle":"2024-10-21T05:40:33.149041Z","shell.execute_reply":"2024-10-21T05:40:33.148006Z","shell.execute_reply.started":"2024-10-21T05:40:29.996242Z"},"trusted":true},"outputs":[],"source":["# convert all our data into torch tensors, required data type for our model\n","train_inputs = torch.tensor(train_inputs)\n","validation_inputs = torch.tensor(validation_inputs)\n","train_labels = torch.tensor(train_labels)\n","validation_labels = torch.tensor(validation_labels)\n","train_masks = torch.tensor(train_masks)\n","validation_masks = torch.tensor(validation_masks)\n","\n","# Select a batch size for training. For fine-tuning BERT on a specific task, the authors recommend a batch size of 16 or 32\n","batch_size = 32\n","\n","# Create an iterator of our data with torch DataLoader. This helps save on memory during training because, unlike a for loop, \n","# with an iterator the entire dataset does not need to be loaded into memory\n","train_data = TensorDataset(train_inputs,train_masks,train_labels)\n","train_sampler = RandomSampler(train_data)\n","train_dataloader = DataLoader(train_data,sampler=train_sampler,batch_size=batch_size)\n","\n","validation_data = TensorDataset(validation_inputs,validation_masks,validation_labels)\n","validation_sampler = RandomSampler(validation_data)\n","validation_dataloader = DataLoader(validation_data,sampler=validation_sampler,batch_size=batch_size)"]},{"cell_type":"markdown","metadata":{},"source":["### Lets see whats there in traindata set "]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:40:37.590697Z","iopub.status.busy":"2024-10-21T05:40:37.590284Z","iopub.status.idle":"2024-10-21T05:40:37.651996Z","shell.execute_reply":"2024-10-21T05:40:37.651022Z","shell.execute_reply.started":"2024-10-21T05:40:37.590659Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(tensor([ 101, 1045, 2123, 1056, 2514, 2061, 9069, 2035, 1996, 2051,  102,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n","            0,    0,    0,    0]),\n"," tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n","         0., 0., 0., 0.]),\n"," tensor(4))"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_data[0]"]},{"cell_type":"code","execution_count":19,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:40:38.829150Z","iopub.status.busy":"2024-10-21T05:40:38.828392Z","iopub.status.idle":"2024-10-21T05:40:38.835342Z","shell.execute_reply":"2024-10-21T05:40:38.834279Z","shell.execute_reply.started":"2024-10-21T05:40:38.829106Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.utils.data.dataloader.DataLoader"]},"execution_count":19,"metadata":{},"output_type":"execute_result"}],"source":["type(train_dataloader)"]},{"cell_type":"code","execution_count":22,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:42:10.174609Z","iopub.status.busy":"2024-10-21T05:42:10.174190Z","iopub.status.idle":"2024-10-21T05:42:10.595735Z","shell.execute_reply":"2024-10-21T05:42:10.594047Z","shell.execute_reply.started":"2024-10-21T05:42:10.174570Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["# Load BertForSequenceClassification, the pretrained BERT model with a single linear classification layer on top. \n","model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=6).to(device)\n","\n","# Parameters:\n","lr = 2e-5\n","adam_epsilon = 1e-8\n","\n","# Number of training epochs (authors recommend between 2 and 4)\n","epochs = 3\n","\n","num_warmup_steps = 0\n","num_training_steps = len(train_dataloader)*epochs\n","\n","### In Transformers, optimizer and schedules are splitted and instantiated like this:\n","optimizer = AdamW(model.parameters(), lr=lr,eps=adam_epsilon,correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n","scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=num_warmup_steps, num_training_steps=num_training_steps)  # PyTorch scheduler"]},{"cell_type":"code","execution_count":23,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T05:42:21.822849Z","iopub.status.busy":"2024-10-21T05:42:21.821971Z","iopub.status.idle":"2024-10-21T06:04:09.881028Z","shell.execute_reply":"2024-10-21T06:04:09.879854Z","shell.execute_reply.started":"2024-10-21T05:42:21.822810Z"},"trusted":true},"outputs":[{"data":{"application/vnd.jupyter.widget-view+json":{"model_id":"26945e376b11483199c70a3e3e8379be","version_major":2,"version_minor":0},"text/plain":["Epoch:   0%|          | 0/3 [00:00<?, ?it/s]"]},"metadata":{},"output_type":"display_data"},{"name":"stdout","output_type":"stream","text":["<====================== Epoch 1 ======================>\n","\n","\tCurrent Learning rate:  1.3333333333333333e-05\n","\n","\tAverage Training loss: 0.3660123776942227\n","\n","\tValidation Accuracy: 0.9330357142857143\n","\n","\tValidation MCC Accuracy: 0.9123689561169931\n","<====================== Epoch 2 ======================>\n","\n","\tCurrent Learning rate:  6.666666666666667e-06\n","\n","\tAverage Training loss: 0.11291385129082544\n","\n","\tValidation Accuracy: 0.9305555555555556\n","\n","\tValidation MCC Accuracy: 0.9085468842200419\n","<====================== Epoch 3 ======================>\n","\n","\tCurrent Learning rate:  0.0\n","\n","\tAverage Training loss: 0.08024320069995756\n","\n","\tValidation Accuracy: 0.9315476190476191\n","\n","\tValidation MCC Accuracy: 0.9108092387714716\n"]}],"source":["import tqdm\n","## Store our loss and accuracy for plotting\n","train_loss_set = []\n","learning_rate = []\n","\n","# Gradients gets accumulated by default\n","model.zero_grad()\n","\n","# tnrange is a tqdm wrapper around the normal python range\n","for _ in tqdm.notebook.trange(1,epochs+1,desc='Epoch'):\n","  print(\"<\" + \"=\"*22 + F\" Epoch {_} \"+ \"=\"*22 + \">\")\n","  # Calculate total loss for this epoch\n","  batch_loss = 0\n","\n","  for step, batch in enumerate(train_dataloader):\n","    # Set our model to training mode (as opposed to evaluation mode)\n","    model.train()\n","    \n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    # Forward pass\n","    outputs = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","    loss = outputs[0]\n","    \n","    # Backward pass\n","    loss.backward()\n","    \n","    # Clip the norm of the gradients to 1.0\n","    # Gradient clipping is not in AdamW anymore\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n","    \n","    # Update parameters and take a step using the computed gradient\n","    optimizer.step()\n","    \n","    # Update learning rate schedule\n","    scheduler.step()\n","\n","    # Clear the previous accumulated gradients\n","    optimizer.zero_grad()\n","    \n","    # Update tracking variables\n","    batch_loss += loss.item()\n","\n","  # Calculate the average loss over the training data.\n","  avg_train_loss = batch_loss / len(train_dataloader)\n","\n","  #store the current learning rate\n","  for param_group in optimizer.param_groups:\n","    print(\"\\n\\tCurrent Learning rate: \",param_group['lr'])\n","    learning_rate.append(param_group['lr'])\n","    \n","  train_loss_set.append(avg_train_loss)\n","  print(F'\\n\\tAverage Training loss: {avg_train_loss}')\n","    \n","  # Validation\n","\n","  # Put model in evaluation mode to evaluate loss on the validation set\n","  model.eval()\n","\n","  # Tracking variables \n","  eval_accuracy,eval_mcc_accuracy,nb_eval_steps = 0, 0, 0\n","\n","  # Evaluate data for one epoch\n","  for batch in validation_dataloader:\n","    # Add batch to GPU\n","    batch = tuple(t.to(device) for t in batch)\n","    # Unpack the inputs from our dataloader\n","    b_input_ids, b_input_mask, b_labels = batch\n","    # Telling the model not to compute or store gradients, saving memory and speeding up validation\n","    with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","    \n","    # Move logits and labels to CPU\n","    logits = logits[0].to('cpu').numpy()\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    pred_flat = np.argmax(logits, axis=1).flatten()\n","    labels_flat = label_ids.flatten()\n","    \n","    df_metrics=pd.DataFrame({'Epoch':epochs,'Actual_class':labels_flat,'Predicted_class':pred_flat})\n","    \n","    tmp_eval_accuracy = accuracy_score(labels_flat,pred_flat)\n","    tmp_eval_mcc_accuracy = matthews_corrcoef(labels_flat, pred_flat)\n","    \n","    eval_accuracy += tmp_eval_accuracy\n","    eval_mcc_accuracy += tmp_eval_mcc_accuracy\n","    nb_eval_steps += 1\n","\n","  print(F'\\n\\tValidation Accuracy: {eval_accuracy/nb_eval_steps}')\n","  print(F'\\n\\tValidation MCC Accuracy: {eval_mcc_accuracy/nb_eval_steps}')"]},{"cell_type":"code","execution_count":24,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:04:34.380434Z","iopub.status.busy":"2024-10-21T06:04:34.380031Z","iopub.status.idle":"2024-10-21T06:04:34.669120Z","shell.execute_reply":"2024-10-21T06:04:34.668112Z","shell.execute_reply.started":"2024-10-21T06:04:34.380392Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[<matplotlib.lines.Line2D at 0x7a1610d918a0>]"]},"execution_count":24,"metadata":{},"output_type":"execute_result"},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["plt.plot(train_loss_set)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":[]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:04:42.582925Z","iopub.status.busy":"2024-10-21T06:04:42.581983Z","iopub.status.idle":"2024-10-21T06:04:42.588231Z","shell.execute_reply":"2024-10-21T06:04:42.587203Z","shell.execute_reply.started":"2024-10-21T06:04:42.582881Z"},"trusted":true},"outputs":[],"source":["%matplotlib inline \n","import matplotlib.pyplot as plt"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:04:43.827928Z","iopub.status.busy":"2024-10-21T06:04:43.826940Z","iopub.status.idle":"2024-10-21T06:04:43.834072Z","shell.execute_reply":"2024-10-21T06:04:43.833020Z","shell.execute_reply.started":"2024-10-21T06:04:43.827881Z"},"trusted":true},"outputs":[{"data":{"text/plain":["torch.Size([16, 256])"]},"execution_count":26,"metadata":{},"output_type":"execute_result"}],"source":["b_input_ids.shape"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:04:47.087909Z","iopub.status.busy":"2024-10-21T06:04:47.087503Z","iopub.status.idle":"2024-10-21T06:04:47.351474Z","shell.execute_reply":"2024-10-21T06:04:47.350466Z","shell.execute_reply.started":"2024-10-21T06:04:47.087871Z"},"trusted":true},"outputs":[{"data":{"text/plain":["SequenceClassifierOutput(loss=None, logits=tensor([[-0.6833,  6.9538, -0.8689, -1.1717, -1.0818, -0.7637],\n","        [-1.6637, -1.7180,  6.6948, -1.9160, -2.2994, -1.8961],\n","        [-1.0564,  4.1658, -1.6999, -1.5707, -1.4272,  3.5267],\n","        [ 6.6188, -1.3588, -1.7036, -1.3558, -1.8396, -1.0008],\n","        [-1.5659, -0.9760, -1.0369, -0.6519, -1.5284,  5.7432],\n","        [-2.1699, -2.1072,  6.7575, -1.4923, -2.2768, -1.6106],\n","        [ 6.7102, -1.0495, -1.7205, -1.2574, -1.9448, -1.2719],\n","        [-1.9306, -1.8815,  6.7013, -1.8484, -1.9256, -1.9217],\n","        [-1.2188, -1.4989, -1.2128,  6.4547, -1.6548, -0.7014],\n","        [-2.0704, -2.1368,  6.6221, -2.0003, -2.0981, -1.1151],\n","        [-1.0849,  6.9879, -0.9444, -1.5881, -0.3065, -0.6805],\n","        [-0.5312, -1.3282, -2.1961, -1.5247,  6.9201, -1.4847],\n","        [-1.4292, -0.1255,  5.9249, -1.9667, -1.8283, -2.8142],\n","        [-1.5392, -1.7349, -0.8187,  6.4641, -1.4668, -1.0430],\n","        [-1.7290, -1.2124, -1.7571, -1.4019,  7.0493, -1.2291],\n","        [-1.6399, -1.8871,  6.6860, -1.9283, -2.1649, -1.8349]],\n","       device='cuda:0', grad_fn=<AddmmBackward0>), hidden_states=None, attentions=None)"]},"execution_count":27,"metadata":{},"output_type":"execute_result"}],"source":["logits = model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)\n","logits"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:05:00.476871Z","iopub.status.busy":"2024-10-21T06:05:00.475899Z","iopub.status.idle":"2024-10-21T06:05:00.487112Z","shell.execute_reply":"2024-10-21T06:05:00.486131Z","shell.execute_reply.started":"2024-10-21T06:05:00.476825Z"},"trusted":true},"outputs":[],"source":["from sklearn.metrics import confusion_matrix,classification_report\n","def plot_confusion_matrix(cm, classes,\n","                          normalize=False,\n","                          title='Confusion matrix',\n","                          cmap=plt.cm.Blues):\n","    \"\"\"\n","    This function prints and plots the confusion matrix.\n","    Normalization can be applied by setting `normalize=True`.\n","    \"\"\"\n","    import itertools\n","    if normalize:\n","        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n","        print(\"Normalized confusion matrix\")\n","    else:\n","        print('Confusion matrix, without normalization')\n","\n","    print(cm)\n","\n","    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n","    plt.title(title)\n","    plt.colorbar()\n","    tick_marks = np.arange(len(classes))\n","    plt.xticks(tick_marks, classes, rotation=45)\n","    plt.yticks(tick_marks, classes)\n","\n","    fmt = '.2f' if normalize else 'd'\n","    thresh = cm.max() / 2.\n","    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n","        plt.text(j, i, format(cm[i, j], fmt),\n","                 horizontalalignment=\"center\",\n","                 color=\"white\" if cm[i, j] > thresh else \"black\")\n","\n","    plt.ylabel('True label')\n","    plt.xlabel('Predicted label')\n","    plt.tight_layout()"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:05:08.465142Z","iopub.status.busy":"2024-10-21T06:05:08.464313Z","iopub.status.idle":"2024-10-21T06:05:08.480743Z","shell.execute_reply":"2024-10-21T06:05:08.479765Z","shell.execute_reply.started":"2024-10-21T06:05:08.465097Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>label_desc</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>4</td>\n","      <td>sadness</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0</td>\n","      <td>anger</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>love</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>5</td>\n","      <td>surprise</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>1</td>\n","      <td>fear</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>2</td>\n","      <td>joy</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label label_desc\n","0      4    sadness\n","2      0      anger\n","3      3       love\n","6      5   surprise\n","7      1       fear\n","8      2        joy"]},"execution_count":29,"metadata":{},"output_type":"execute_result"}],"source":["df[['label','label_desc']].drop_duplicates(keep='first')"]},{"cell_type":"code","execution_count":31,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:05:37.707337Z","iopub.status.busy":"2024-10-21T06:05:37.706610Z","iopub.status.idle":"2024-10-21T06:05:37.712106Z","shell.execute_reply":"2024-10-21T06:05:37.710909Z","shell.execute_reply.started":"2024-10-21T06:05:37.707296Z"},"trusted":true},"outputs":[],"source":["## emotion labels\n","label2int = {\n","  \"sadness\": 4,\n","  \"joy\": 2,\n","  \"anger\": 0,\n","  \"fear\": 1,\n","  \"surprise\": 5,\n","    \"love\":3\n","}"]},{"cell_type":"code","execution_count":32,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:05:40.288311Z","iopub.status.busy":"2024-10-21T06:05:40.287631Z","iopub.status.idle":"2024-10-21T06:05:40.295334Z","shell.execute_reply":"2024-10-21T06:05:40.294259Z","shell.execute_reply.started":"2024-10-21T06:05:40.288262Z"},"trusted":true},"outputs":[{"data":{"text/plain":["array([1, 2, 0, 5, 3, 4])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":[" df_metrics['Predicted_class'].unique()"]},{"cell_type":"code","execution_count":33,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:05:48.653694Z","iopub.status.busy":"2024-10-21T06:05:48.652704Z","iopub.status.idle":"2024-10-21T06:05:48.667115Z","shell.execute_reply":"2024-10-21T06:05:48.666200Z","shell.execute_reply.started":"2024-10-21T06:05:48.653650Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","     sadness   1.000000  1.000000  1.000000         2\n","         joy   1.000000  1.000000  1.000000         3\n","       anger   1.000000  1.000000  1.000000         6\n","        fear   1.000000  1.000000  1.000000         2\n","    surprise   1.000000  1.000000  1.000000         2\n","        love   1.000000  1.000000  1.000000         1\n","\n","    accuracy                       1.000000        16\n","   macro avg   1.000000  1.000000  1.000000        16\n","weighted avg   1.000000  1.000000  1.000000        16\n","\n"]}],"source":["print(classification_report(df_metrics['Actual_class'].values, df_metrics['Predicted_class'].values, target_names=label2int.keys(), digits=len(label2int)))"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:05:54.711792Z","iopub.status.busy":"2024-10-21T06:05:54.710886Z","iopub.status.idle":"2024-10-21T06:05:54.718032Z","shell.execute_reply":"2024-10-21T06:05:54.716737Z","shell.execute_reply.started":"2024-10-21T06:05:54.711749Z"},"trusted":true},"outputs":[{"data":{"text/plain":["(16, 3)"]},"execution_count":34,"metadata":{},"output_type":"execute_result"}],"source":["df_metrics.shape"]},{"cell_type":"code","execution_count":35,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:05:56.146878Z","iopub.status.busy":"2024-10-21T06:05:56.145967Z","iopub.status.idle":"2024-10-21T06:05:56.153448Z","shell.execute_reply":"2024-10-21T06:05:56.152483Z","shell.execute_reply.started":"2024-10-21T06:05:56.146837Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2837: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n","  warnings.warn(\n"]}],"source":["text = \"I'm very Happy\"\n","input_ids_test = tokenizer.encode(text, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True) \n","attention_mask = [float(i>0) for i in input_ids_test]\n","att = torch.tensor([attention_mask])\n","t = torch.tensor([input_ids_test])"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:06:01.337694Z","iopub.status.busy":"2024-10-21T06:06:01.337277Z","iopub.status.idle":"2024-10-21T06:06:01.343089Z","shell.execute_reply":"2024-10-21T06:06:01.342020Z","shell.execute_reply.started":"2024-10-21T06:06:01.337655Z"},"trusted":true},"outputs":[],"source":["att = att.to(model.device)\n","t = t.to(model.device)"]},{"cell_type":"code","execution_count":37,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:06:03.482302Z","iopub.status.busy":"2024-10-21T06:06:03.481854Z","iopub.status.idle":"2024-10-21T06:06:03.487820Z","shell.execute_reply":"2024-10-21T06:06:03.486825Z","shell.execute_reply.started":"2024-10-21T06:06:03.482263Z"},"trusted":true},"outputs":[],"source":["\n","# Set the batch size.  \n","batch_size = 16\n","# Create the DataLoader.\n","prediction_data = TensorDataset(t, att)\n","prediction_sampler = RandomSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:06:07.775367Z","iopub.status.busy":"2024-10-21T06:06:07.774441Z","iopub.status.idle":"2024-10-21T06:06:07.806215Z","shell.execute_reply":"2024-10-21T06:06:07.805215Z","shell.execute_reply.started":"2024-10-21T06:06:07.775325Z"},"trusted":true},"outputs":[],"source":["for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","  logits = outputs[0]"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:06:09.996422Z","iopub.status.busy":"2024-10-21T06:06:09.996017Z","iopub.status.idle":"2024-10-21T06:06:10.004085Z","shell.execute_reply":"2024-10-21T06:06:10.003187Z","shell.execute_reply.started":"2024-10-21T06:06:09.996387Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-1.3053, -1.9666,  6.4424, -1.8536, -1.6761, -2.3080]],\n","       device='cuda:0')"]},"execution_count":39,"metadata":{},"output_type":"execute_result"}],"source":["logits "]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:06:12.103733Z","iopub.status.busy":"2024-10-21T06:06:12.102931Z","iopub.status.idle":"2024-10-21T06:06:12.121151Z","shell.execute_reply":"2024-10-21T06:06:12.120298Z","shell.execute_reply.started":"2024-10-21T06:06:12.103690Z"},"trusted":true},"outputs":[],"source":["max_names = [torch.argmax(vals) for vals in logits]"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:06:13.825831Z","iopub.status.busy":"2024-10-21T06:06:13.825439Z","iopub.status.idle":"2024-10-21T06:06:13.832822Z","shell.execute_reply":"2024-10-21T06:06:13.831912Z","shell.execute_reply.started":"2024-10-21T06:06:13.825797Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[tensor(2, device='cuda:0')]"]},"execution_count":41,"metadata":{},"output_type":"execute_result"}],"source":["max_names"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:06:22.019381Z","iopub.status.busy":"2024-10-21T06:06:22.018966Z","iopub.status.idle":"2024-10-21T06:06:26.137540Z","shell.execute_reply":"2024-10-21T06:06:26.136374Z","shell.execute_reply.started":"2024-10-21T06:06:22.019342Z"},"trusted":true},"outputs":[],"source":["model_save_folder = 'model/'\n","tokenizer_save_folder = 'tokenizer/'\n","\n","path_model = F'/kaggle/working/{model_save_folder}'\n","path_tokenizer = F'/kaggle/working/{tokenizer_save_folder}'\n","\n","#create the dir\n","\n","!mkdir -p {path_model}\n","!mkdir -p {path_tokenizer}\n","\n","## Now let's save our model and tokenizer to a directory\n","model.save_pretrained(path_model)\n","tokenizer.save_pretrained(path_tokenizer)\n","\n","model_save_name = 'fineTuneModel.pt'\n","path = path_model = F'/kaggle/working/{model_save_folder}/{model_save_name}'\n","torch.save(model.state_dict(),path);"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:14:31.284848Z","iopub.status.busy":"2024-10-21T06:14:31.284400Z","iopub.status.idle":"2024-10-21T06:15:17.604986Z","shell.execute_reply":"2024-10-21T06:15:17.603198Z","shell.execute_reply.started":"2024-10-21T06:14:31.284808Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: model/ (stored 0%)\n","  adding: model/fineTuneModel.pt (deflated 7%)\n","  adding: model/config.json (deflated 54%)\n","  adding: model/model.safetensors (deflated 7%)\n"]}],"source":["!zip -r model.zip 'model'"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:15:37.792936Z","iopub.status.busy":"2024-10-21T06:15:37.792487Z","iopub.status.idle":"2024-10-21T06:15:38.829807Z","shell.execute_reply":"2024-10-21T06:15:38.828646Z","shell.execute_reply.started":"2024-10-21T06:15:37.792894Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["  adding: tokenizer/ (stored 0%)\n","  adding: tokenizer/tokenizer_config.json (deflated 75%)\n","  adding: tokenizer/special_tokens_map.json (deflated 42%)\n","  adding: tokenizer/vocab.txt (deflated 53%)\n"]}],"source":["!zip -r tokenizer.zip 'tokenizer'"]},{"cell_type":"code","execution_count":49,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:17:39.931196Z","iopub.status.busy":"2024-10-21T06:17:39.929757Z","iopub.status.idle":"2024-10-21T06:17:39.939553Z","shell.execute_reply":"2024-10-21T06:17:39.938496Z","shell.execute_reply.started":"2024-10-21T06:17:39.931131Z"},"trusted":true},"outputs":[],"source":["text = \"I can go from feeling so hopeless to so damned hopeful just from being around someone who cares and is awake\"\n","input_ids_test = tokenizer.encode(text, add_special_tokens=True,max_length=MAX_LEN,pad_to_max_length=True) \n","attention_mask = [float(i>0) for i in input_ids_test]\n","att = torch.tensor([attention_mask])\n","t = torch.tensor([input_ids_test])"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:18:02.164686Z","iopub.status.busy":"2024-10-21T06:18:02.164216Z","iopub.status.idle":"2024-10-21T06:18:02.170146Z","shell.execute_reply":"2024-10-21T06:18:02.169127Z","shell.execute_reply.started":"2024-10-21T06:18:02.164638Z"},"trusted":true},"outputs":[],"source":["att = att.to(model.device)\n","t = t.to(model.device)"]},{"cell_type":"code","execution_count":52,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:18:18.179367Z","iopub.status.busy":"2024-10-21T06:18:18.178438Z","iopub.status.idle":"2024-10-21T06:18:18.184564Z","shell.execute_reply":"2024-10-21T06:18:18.183555Z","shell.execute_reply.started":"2024-10-21T06:18:18.179324Z"},"trusted":true},"outputs":[],"source":["# Set the batch size.  \n","batch_size = 16\n","# Create the DataLoader.\n","prediction_data = TensorDataset(t, att)\n","prediction_sampler = RandomSampler(prediction_data)\n","prediction_dataloader = DataLoader(prediction_data, sampler=prediction_sampler, batch_size=batch_size)"]},{"cell_type":"code","execution_count":53,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:18:30.655839Z","iopub.status.busy":"2024-10-21T06:18:30.655034Z","iopub.status.idle":"2024-10-21T06:18:30.676481Z","shell.execute_reply":"2024-10-21T06:18:30.675541Z","shell.execute_reply.started":"2024-10-21T06:18:30.655798Z"},"trusted":true},"outputs":[],"source":["for batch in prediction_dataloader:\n","  # Add batch to GPU\n","  batch = tuple(t.to(device) for t in batch)\n","  \n","  # Unpack the inputs from our dataloader\n","  b_input_ids, b_input_mask = batch\n","  \n","  # Telling the model not to compute or store gradients, saving memory and \n","  # speeding up prediction\n","  with torch.no_grad():\n","      # Forward pass, calculate logit predictions\n","      outputs = model(b_input_ids, token_type_ids=None, \n","                      attention_mask=b_input_mask)\n","  logits = outputs[0]"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:18:40.366549Z","iopub.status.busy":"2024-10-21T06:18:40.365560Z","iopub.status.idle":"2024-10-21T06:18:40.374779Z","shell.execute_reply":"2024-10-21T06:18:40.373772Z","shell.execute_reply.started":"2024-10-21T06:18:40.366505Z"},"trusted":true},"outputs":[{"data":{"text/plain":["tensor([[-1.9852, -1.2082, -1.7020, -1.2262,  6.9261, -1.1565]],\n","       device='cuda:0')"]},"execution_count":54,"metadata":{},"output_type":"execute_result"}],"source":["logits "]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:18:46.742878Z","iopub.status.busy":"2024-10-21T06:18:46.741931Z","iopub.status.idle":"2024-10-21T06:18:46.747876Z","shell.execute_reply":"2024-10-21T06:18:46.746904Z","shell.execute_reply.started":"2024-10-21T06:18:46.742834Z"},"trusted":true},"outputs":[],"source":["max_names = [torch.argmax(vals) for vals in logits]"]},{"cell_type":"code","execution_count":57,"metadata":{"execution":{"iopub.execute_input":"2024-10-21T06:19:07.755040Z","iopub.status.busy":"2024-10-21T06:19:07.754344Z","iopub.status.idle":"2024-10-21T06:19:07.761895Z","shell.execute_reply":"2024-10-21T06:19:07.760926Z","shell.execute_reply.started":"2024-10-21T06:19:07.754994Z"},"trusted":true},"outputs":[{"data":{"text/plain":["[tensor(4, device='cuda:0')]"]},"execution_count":57,"metadata":{},"output_type":"execute_result"}],"source":["list(max_names)"]}],"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"datasetId":605165,"sourceId":1085454,"sourceType":"datasetVersion"}],"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
